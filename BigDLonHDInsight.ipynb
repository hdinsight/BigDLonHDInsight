{"nbformat_minor": 1, "cells": [{"source": "### What's BigDL\n\nIn 2016, Intel released its BigDL distributed Deep Learning project into the open-source community. It natively integrates into Spark framework and supports popular neural net topologies. BigDL also provides 100+ basic building blocks for neural networks allowing users to create novel topologies to suit their unique applications. Thus with Intel\u2019s BigDL, the users are able to leverage their existing Spark infrastructure to enable Deep Learning applications without having to invest into bringing up separate infrastructure to take advantage of neural networks. Since BigDL is an integral part of Spark framework, the user does not need explicitly manage distributed computations. Instead, BigDL and Spark do it for him/her, while allowing sufficient level of optimization and customization of compute execution. See below for details and check out Intel\u2019s BigDL portal. \n\nIn the notebook, we will desmonstrate how to train lenet on mnist in BigDL. For more detail, see https://github.com/intel-analytics/BigDL/wiki/Tutorials#training-lenet-on-mnist", "cell_type": "markdown", "metadata": {}}, {"source": "### Set enviroment variables\n\nBigDL leverages Intel MKL kernels. Therefore, a few special env variable need to be set in executors for a optimal performance. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%configure -f\n\n{ \n    \"jars\":[\"wasb:///bigdl-0.1.0-SNAPSHOT-jar-with-dependencies2.jar\"],\n    \n    \"conf\": {\n        \"spark.executorEnv.DL_ENGINE_TYPE\": \"mklblas\",\n        \"spark.executorEnv.MKL_DISABLE_FAST_MM\": \"1\",\n        \"spark.executorEnv.KMP_BLOCKTIME\": \"0\",\n        \"spark.executorEnv.OMP_WAIT_POLICY\": \"passive\",\n        \"spark.executorEnv.OMP_NUM_THREADS\": \"1\",\n        \"spark.executorEnv.DL_CORE_NUMBER\": \"7\",\n        \"spark.executorEnv.DL_NODE_NUMBER\": \"4\",\n        \"spark.driver.extraJavaOptions\": \"-Dbigdl.check.singleton=false\"\n}\n}", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Set Cluster Depenedent Parameters\nOther cluster-dependent parameters also need to be passed (e.g. executor cores number) and some Spark properties need be set correctly. After set coreNumber, nodeNumber, we need initialize Engine. The Engine will appropriately initialize executor environment variables and spark properties in order to get the best performance for your deep learning application on Spark cluster. Note:\n1.\tCore number should be less than the number of physical cores available. If your machine turns on hyper-threading, one physical core will map to two OS cores. The higher the core number, the better training speed we can get. You can get the core number by going to the YARN UI of your cluster (https://clusteraddress.azurehdinsight.net/yarnui). In this example, we use a cluster that has 4 nodes and each node has 8 cores,\n2.\tThe totalBatch means  total batch size. In a distributed environment, the batch_size should be divided by nodeNumber *coreNumber", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "/*\n * --coreNumber: Core number used in the training per node. \n * --nodeNumber: Executor number in cluster.\n * --batchsize: Mini batch size.\n */\nimport com.intel.analytics.bigdl.utils.Engine\nval nodeNumber = 4\nval coreNumber = 7\nval mult = 64\nval batchSize = nodeNumber * coreNumber * mult\nEngine.init(nodeNumber, coreNumber, true /* env == \"spark\" */)", "outputs": [], "metadata": {"scrolled": true, "collapsed": false}}, {"source": "### Prepare dataset\n\nWe use MNIST as our dataset. It is a database of handwritten digits and the digits have been size-normalized and centered in a fixed-size image. Therefore it's a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. There are four files in the dataset. train-images-idx3-ubyte contains train images, train-labels-idx1-ubyte is a train label file, t10k-images-idx3-ubyte has validation images and t10k-labels-idx1-ubyte contains validation labels.\n\nYou should put all the MNIST dataset in the default storage account (the BLOB storage).", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "/* \n * Load data from files\n */\nimport java.nio.ByteBuffer\nimport java.nio.file.Path\nimport com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.dataset.image._\nimport com.intel.analytics.bigdl.models.lenet.Utils\n\ndef loadBinaryFile(filePath: Path): Array[Byte] = {\n  val files = sc.binaryFiles(filePath.toString())\n  val bytes = files.first()._2.toArray()\n  bytes\n}\n\ndef load(featureFile: Path, labelFile: Path): Array[ByteRecord] = {\n  val labelBuffer = ByteBuffer.wrap(loadBinaryFile(labelFile))\n  val featureBuffer = ByteBuffer.wrap(loadBinaryFile(featureFile))\n  val labelMagicNumber = labelBuffer.getInt()\n\n  require(labelMagicNumber == 2049)\n  val featureMagicNumber = featureBuffer.getInt()\n  require(featureMagicNumber == 2051)\n\n  val labelCount = labelBuffer.getInt()\n  val featureCount = featureBuffer.getInt()\n  require(labelCount == featureCount)\n\n  val rowNum = featureBuffer.getInt()\n  val colNum = featureBuffer.getInt()\n\n  val result = new Array[ByteRecord](featureCount)\n  var i = 0\n  while (i < featureCount) {\n    val img = new Array[Byte]((rowNum * colNum))\n    var y = 0\n    while (y < rowNum) {\n      var x = 0\n      while (x < colNum) {\n        img(x + y * colNum) = featureBuffer.get()\n        x += 1\n      }\n      y += 1\n    }\n    result(i) = ByteRecord(img, labelBuffer.get().toFloat + 1.0f)\n    i += 1\n  }\n  result\n}", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "// Files used for training\nval dir = \"/mnistdataset\"\nval dbfsDir = dir\n\nval trainDataFile = \"train-images-idx3-ubyte\"\nval trainLabelFile = \"train-labels-idx1-ubyte\"\nval validationDataFile = \"t10k-images-idx3-ubyte\"\nval validationLabelFile = \"t10k-labels-idx1-ubyte\"", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Here we load data from MINIST by creating the BigDL DataSet , and then applying a series of Transformer to preprocess data into Mini-batch.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "/* Preprocess data, Convert byte records into grey image, \n * normalize it and convert a batch of labeled grey\n * images into a Mini-batch\n */\nimport java.nio.file.Paths\nimport com.intel.analytics.bigdl.DataSet\nimport com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.dataset.image._\nval trainData = Paths.get(dbfsDir, trainDataFile)\nval trainLabel = Paths.get(dbfsDir, trainLabelFile)\nval validationData = Paths.get(dbfsDir, validationDataFile)\nval validationLabel = Paths.get(dbfsDir, validationLabelFile)\n\nval trainMean = 0.13066047740239506\nval trainStd = 0.3081078\nval trainSet = DataSet.array(load(trainData, trainLabel), sc) -> BytesToGreyImg(28, 28) -> GreyImgNormalizer(trainMean, trainStd) -> GreyImgToBatch(batchSize)\n\nval testMean = 0.13251460696903547\nval testStd = 0.31048024\nval validationSet = DataSet.array(load(validationData, validationLabel), sc) -> BytesToGreyImg(28, 28) -> GreyImgNormalizer(testMean, testStd) -> GreyImgToBatch(batchSize)\n", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Train model\n\nBefore training, we need set hyperparameters which determine how the network is trained. For more details, see http://colinraffel.com/wiki/neural_network_hyperparameters\n\nAnd we use LeNet5 as our training model. LeNet5 is a classical CNN model used in digital number classification. For detailed information, please refer to http://yann.lecun.com/exdb/lenet/ \n\nThen we create the Optimizer by specifying the DataSet, the Model and the Criterion (which, given input and target, computes gradient per given loss function) and begin training. The training step may take a while on a small number of nodes. Using a compute cluster will speed up training significantly.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import com.intel.analytics.bigdl.models.lenet._\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.utils._\n\n// Set hyperparameters. we set learningrate and max epoches here\nval state = T(\"learningRate\" -> 0.05 / 4 * mult)\n\n// Set maximun epoches\nval maxEpoch = 15\n\n// Train Lenet model\nval initialModel = LeNet5(10)  // 10 digit classes\nval optimizer = Optimizer(\n  model = initialModel,   // training modes\n  dataset = trainSet,     // training dataset\n  criterion = ClassNLLCriterion[Float]()) // loss function\nval trainedModel = optimizer.setValidation(\n    trigger = Trigger.everyEpoch,\n    dataset = validationSet,\n    vMethods = Array(new Top1Accuracy)).setState(state).setEndWhen(Trigger.maxEpoch(maxEpoch)).optimize()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Validate model\n\nNow we can validate the learned model. BigDL provides a set of metrics to evaluate the model via Validator and ValidationMethod classes. Here we use Top1Accuracy as validationMethod. It will calculate top 1 accuracy.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "// Validate the learned model\nimport com.intel.analytics.bigdl.optim.{LocalValidator, Top1Accuracy, Validator}\nval validator = Validator(trainedModel, validationSet)\nval result = validator.test(Array(new Top1Accuracy[Float]))\nresult.foreach(r => {\n  println(s\"${r._2} is ${r._1}\")\n})", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Looking at the result\nYou should be able to see a model that has top 1 accuracy bigger than 98%. ", "cell_type": "markdown", "metadata": {}}, {"source": "### Conclusion\nIn this blog post, we have demonstrated how easy it is to set up a BigDL environment on HDInsight Spark. Leveraging BigDL Spark library, a user can easily write scalable distributed Deep Learning applications within familiar Spark infrastructure without an intimate knowledge of the configuration of the underlying compute cluster. BigDL and Azure HDInsight team have been collaborating closely enable BigDL in Azure HDInsight environment.\nIf you have any feedbacks for HDInsight, feel free to drop an email to hdifeedback at microsoft dot com. If you have any questions for BigDL, you can raise your questions in BigDL Google Group (https://groups.google.com/forum/#!forum/bigdl-user-group).\n", "cell_type": "markdown", "metadata": {}}, {"source": "### Resources\n[Learn more about Azure HDInsight](https://docs.microsoft.com/en-us/azure/hdinsight/)\n\n[Aritificial Intelligence Software and Hardware at Intel](https://software.intel.com/ai)\n\n[BigDL introductory video](https://software.intel.com/en-us/videos/bigdl-distributed-deep-learning-on-apache-spark)\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}